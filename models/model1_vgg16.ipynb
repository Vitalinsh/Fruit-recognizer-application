{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16, VGG19, Xception\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(\"dataset\", \"training\")\n",
    "valid_path = os.path.join(\"dataset\", \"validation\")\n",
    "test_path = os.path.join(\"dataset\", \"test_new\")\n",
    "classes = ['Apple Red Yellow', 'Apple Golden 1', 'Avocado', 'Avocado ripe', 'Banana',\n",
    "          'Cocos', 'Dates', 'Granadilla', 'Grape Pink', 'Grape White',\n",
    "          'Kiwi', 'Kumquats', 'Lemon', 'Lemon Meyer', 'Limes',\n",
    "          'Nectarine', 'Orange', 'Peach', 'Peach Flat', 'Apricot']\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width, n_channels = 100, 100, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9719 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator =  datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    classes=classes,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1632 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator =  datagen.flow_from_directory(\n",
    "    valid_path,\n",
    "    classes=classes,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1633 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator =  datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    classes=classes,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1. Pretrained VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_net = VGG16(weights='imagenet', \n",
    "                  include_top=False, \n",
    "                  input_shape=(img_width, img_height, n_channels))\n",
    "vgg16_net.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 3, 3, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 15,931,604\n",
      "Trainable params: 1,216,148\n",
      "Non-trainable params: 14,715,456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(vgg16_net)\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(n_classes, activation=\"softmax\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=l2(0.01)))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam(lr=1e-5), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorBoard(log_dir=\"tb_logs\", histogram_freq=1, write_images=True)\n",
    "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "            ModelCheckpoint(\"saved_models/model1_vgg16_best1_weights.hdf5\", save_best_only=True, monitor=\"val_loss\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "304/304 [==============================] - 152s 501ms/step - loss: 6.9979 - acc: 0.6953 - val_loss: 6.4825 - val_acc: 0.8873\n",
      "Epoch 2/30\n",
      "304/304 [==============================] - 148s 487ms/step - loss: 6.6229 - acc: 0.7436 - val_loss: 6.1692 - val_acc: 0.9038\n",
      "Epoch 3/30\n",
      "304/304 [==============================] - 148s 488ms/step - loss: 6.3013 - acc: 0.7825 - val_loss: 5.8982 - val_acc: 0.9240\n",
      "Epoch 4/30\n",
      "304/304 [==============================] - 148s 488ms/step - loss: 6.0242 - acc: 0.8158 - val_loss: 5.6632 - val_acc: 0.9289\n",
      "Epoch 5/30\n",
      "304/304 [==============================] - 148s 487ms/step - loss: 5.7696 - acc: 0.8472 - val_loss: 5.4638 - val_acc: 0.9479\n",
      "Epoch 6/30\n",
      "304/304 [==============================] - 148s 488ms/step - loss: 5.5657 - acc: 0.8642 - val_loss: 5.2875 - val_acc: 0.9522\n",
      "Epoch 7/30\n",
      "304/304 [==============================] - 148s 487ms/step - loss: 5.3648 - acc: 0.8797 - val_loss: 5.0985 - val_acc: 0.9626\n",
      "Epoch 8/30\n",
      "304/304 [==============================] - 148s 487ms/step - loss: 5.1886 - acc: 0.8959 - val_loss: 4.9552 - val_acc: 0.9602\n",
      "Epoch 9/30\n",
      "304/304 [==============================] - 148s 487ms/step - loss: 5.0103 - acc: 0.9125 - val_loss: 4.7972 - val_acc: 0.9737\n",
      "Epoch 10/30\n",
      "304/304 [==============================] - 148s 487ms/step - loss: 4.8583 - acc: 0.9224 - val_loss: 4.6585 - val_acc: 0.9743\n",
      "Epoch 11/30\n",
      "304/304 [==============================] - 148s 487ms/step - loss: 4.7007 - acc: 0.9332 - val_loss: 4.5327 - val_acc: 0.9786\n",
      "Epoch 12/30\n",
      "304/304 [==============================] - 148s 487ms/step - loss: 4.5551 - acc: 0.9446 - val_loss: 4.3995 - val_acc: 0.9798\n",
      "Epoch 13/30\n",
      "304/304 [==============================] - 148s 487ms/step - loss: 4.4271 - acc: 0.9463 - val_loss: 4.2594 - val_acc: 0.9828\n",
      "Epoch 14/30\n",
      "304/304 [==============================] - 148s 487ms/step - loss: 4.2900 - acc: 0.9569 - val_loss: 4.1490 - val_acc: 0.9847\n",
      "Epoch 15/30\n",
      "304/304 [==============================] - 148s 486ms/step - loss: 4.1618 - acc: 0.9623 - val_loss: 4.0291 - val_acc: 0.9865\n",
      "Epoch 16/30\n",
      "304/304 [==============================] - 148s 488ms/step - loss: 4.0394 - acc: 0.9655 - val_loss: 3.9088 - val_acc: 0.9853\n",
      "Epoch 17/30\n",
      "304/304 [==============================] - 148s 486ms/step - loss: 3.9183 - acc: 0.9694 - val_loss: 3.8052 - val_acc: 0.9865\n",
      "Epoch 18/30\n",
      "304/304 [==============================] - 360s 1s/step - loss: 3.8059 - acc: 0.9727 - val_loss: 3.6930 - val_acc: 0.9877\n",
      "Epoch 19/30\n",
      "304/304 [==============================] - 149s 489ms/step - loss: 3.6935 - acc: 0.9759 - val_loss: 3.5877 - val_acc: 0.9853\n",
      "Epoch 20/30\n",
      "304/304 [==============================] - 148s 487ms/step - loss: 3.5770 - acc: 0.9816 - val_loss: 3.4853 - val_acc: 0.9865\n",
      "Epoch 21/30\n",
      "304/304 [==============================] - 148s 488ms/step - loss: 3.4720 - acc: 0.9827 - val_loss: 3.3805 - val_acc: 0.9890\n",
      "Epoch 22/30\n",
      "304/304 [==============================] - 148s 488ms/step - loss: 3.3711 - acc: 0.9815 - val_loss: 3.2809 - val_acc: 0.9926\n",
      "Epoch 23/30\n",
      "304/304 [==============================] - 149s 491ms/step - loss: 3.2716 - acc: 0.9851 - val_loss: 3.1877 - val_acc: 0.9908\n",
      "Epoch 24/30\n",
      "304/304 [==============================] - 150s 492ms/step - loss: 3.1686 - acc: 0.9865 - val_loss: 3.0930 - val_acc: 0.9871\n",
      "Epoch 25/30\n",
      "304/304 [==============================] - 149s 490ms/step - loss: 3.0779 - acc: 0.9882 - val_loss: 3.0024 - val_acc: 0.9920\n",
      "Epoch 26/30\n",
      "304/304 [==============================] - 149s 490ms/step - loss: 2.9862 - acc: 0.9893 - val_loss: 2.9207 - val_acc: 0.9871\n",
      "Epoch 27/30\n",
      "304/304 [==============================] - 149s 490ms/step - loss: 2.8968 - acc: 0.9909 - val_loss: 2.8287 - val_acc: 0.9908\n",
      "Epoch 28/30\n",
      "304/304 [==============================] - 149s 491ms/step - loss: 2.8090 - acc: 0.9905 - val_loss: 2.7485 - val_acc: 0.9896\n",
      "Epoch 29/30\n",
      "304/304 [==============================] - 149s 489ms/step - loss: 2.7257 - acc: 0.9914 - val_loss: 2.6685 - val_acc: 0.9865\n",
      "Epoch 30/30\n",
      "304/304 [==============================] - 149s 490ms/step - loss: 2.6438 - acc: 0.9901 - val_loss: 2.5864 - val_acc: 0.9914\n",
      "Wall time: 1h 18min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "       epochs=30,                    \n",
    "       validation_data=valid_generator,\n",
    "       callbacks=callbacks,\n",
    "       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy after last epoch = 0.9920391916717698\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator)\n",
    "print(\"Test accuracy after last epoch =\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"saved_models/model1_vgg16_best2_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best 1 model\n",
    "model.load_weights(\"saved_models/model1_vgg16_best1_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.9920391916717698\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator)\n",
    "print(\"Test accuracy =\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid accuracy = 0.991421568627451\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(valid_generator)\n",
    "print(\"Valid accuracy =\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(train_generator)\n",
    "print(\"Train accuracy =\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = model.to_json()\n",
    "with open(\"saved_models/model1_vgg16_architecture.json\", \"w\") as json_file:\n",
    "    json_file.write(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
